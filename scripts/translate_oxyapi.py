#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OxyAPI æ–‡æ¡£ç¿»è¯‘è„šæœ¬
å°† content/oxyapi/*.mdx ç¿»è¯‘ä¸ºå¯¹åº”çš„ .zh-CN.mdx æ–‡ä»¶
"""

import os
import re
from pathlib import Path

# æœ¯è¯­ç¿»è¯‘æ˜ å°„è¡¨
TERM_TRANSLATIONS = {
    # Frontmatter
    "API Reference": "API å‚è€ƒ",
    "Complete API reference for": "å®Œæ•´ API å‚è€ƒæ–‡æ¡£ï¼š",
    "Complete API documentation for": "å®Œæ•´ API æ–‡æ¡£ï¼š",
    "constructor parameters and methods": "æ„é€ å‡½æ•°å‚æ•°å’Œæ–¹æ³•",
    
    # æ ‡é¢˜
    "Constructor Parameters": "æ„é€ å‡½æ•°å‚æ•°",
    "Core Parameters": "æ ¸å¿ƒå‚æ•°",
    "Execution Parameters": "æ‰§è¡Œå‚æ•°",
    "Memory Parameters": "å†…å­˜å‚æ•°",
    "Configuration Parameters": "é…ç½®å‚æ•°",
    "Callback Parameters": "å›è°ƒå‚æ•°",
    "Advanced Parameters": "é«˜çº§å‚æ•°",
    "Parameter Details": "å‚æ•°è¯¦æƒ…",
    "Methods": "æ–¹æ³•",
    "Usage Guidelines": "ä½¿ç”¨æŒ‡å—",
    "Related Documentation": "ç›¸å…³æ–‡æ¡£",
    "Quick Start": "å¿«é€Ÿå¼€å§‹",
    "API Conventions": "API çº¦å®š",
    "Getting Help": "è·å–å¸®åŠ©",
    "Overview": "æ¦‚è¿°",
    
    # ç« èŠ‚åç§°
    "Agents": "ä»£ç†",
    "Flows": "æµç¨‹",
    "Tools": "å·¥å…·",
    "LLMs": "å¤§è¯­è¨€æ¨¡å‹",
    
    # è¡¨æ ¼æ ‡é¢˜
    "Parameter": "å‚æ•°",
    "Type": "ç±»å‹",
    "Default": "é»˜è®¤å€¼",
    "Description": "æè¿°",
    "Required": "å¿…éœ€",
    "Returns": "è¿”å›å€¼",
    "Example": "ç¤ºä¾‹",
    "Parameters": "å‚æ•°",
    
    # å¸¸ç”¨è¯æ±‡
    "Yes": "æ˜¯",
    "No": "å¦",
    "None": "æ— ",
    "Optional": "å¯é€‰",
    "required": "å¿…éœ€",
    "optional": "å¯é€‰",
}

# å¥å­ç¿»è¯‘æ˜ å°„
SENTENCE_TRANSLATIONS = {
    "Agents are the core components of the OxyGent framework, responsible for executing specific tasks and making decisions.": 
        "ä»£ç†æ˜¯ OxyGent æ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£æ‰§è¡Œç‰¹å®šä»»åŠ¡å’Œåšå‡ºå†³ç­–ã€‚",
    
    "Flow components define the execution logic and decision-making processes of agents.":
        "æµç¨‹ç»„ä»¶å®šä¹‰äº†ä»£ç†çš„æ‰§è¡Œé€»è¾‘å’Œå†³ç­–è¿‡ç¨‹ã€‚",
    
    "LLM components provide integration interfaces with various large language model services.":
        "å¤§è¯­è¨€æ¨¡å‹ç»„ä»¶æä¾›äº†ä¸å„ç§å¤§è¯­è¨€æ¨¡å‹æœåŠ¡çš„é›†æˆæ¥å£ã€‚",
    
    "Tool components provide agents with the ability to interact with external systems.":
        "å·¥å…·ç»„ä»¶ä¸ºä»£ç†æä¾›äº†ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’çš„èƒ½åŠ›ã€‚",
    
    "If you're new to the OxyGent API, we recommend starting with the following steps:":
        "å¦‚æœæ‚¨æ˜¯ OxyGent API çš„æ–°æ‰‹ï¼Œæˆ‘ä»¬å»ºè®®ä»ä»¥ä¸‹æ­¥éª¤å¼€å§‹ï¼š",
    
    "All OxyGent APIs follow these conventions:":
        "æ‰€æœ‰ OxyGent API éƒ½éµå¾ªä»¥ä¸‹çº¦å®šï¼š",
    
    "If you encounter issues while using the API, you can:":
        "å¦‚æœæ‚¨åœ¨ä½¿ç”¨ API æ—¶é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š",
    
    "Check out": "æŸ¥çœ‹",
    "to understand basic agent usage": "ä»¥äº†è§£åŸºæœ¬çš„ä»£ç†ä½¿ç”¨æ–¹æ³•",
    "to understand how to configure large language models": "ä»¥äº†è§£å¦‚ä½•é…ç½®å¤§è¯­è¨€æ¨¡å‹",
    "to understand the tool system": "ä»¥äº†è§£å·¥å…·ç³»ç»Ÿ",
    
    "Refer to specific component API documentation": "å‚è€ƒç‰¹å®šç»„ä»¶çš„ API æ–‡æ¡£",
    "Review code examples and best practices": "æŸ¥çœ‹ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µ",
    "Check the error handling and troubleshooting sections": "æŸ¥çœ‹é”™è¯¯å¤„ç†å’Œæ•…éšœæ’é™¤ç« èŠ‚",
    
    # API æ–‡æ¡£ç‰¹æœ‰å¥å­
    "Unique identifier for the agent": "ä»£ç†çš„å”¯ä¸€æ ‡è¯†ç¬¦",
    "Whether this is the entry point agent": "æ­¤ä»£ç†æ˜¯å¦ä¸ºå…¥å£ä»£ç†",
    "Name of LLM component to use": "è¦ä½¿ç”¨çš„å¤§è¯­è¨€æ¨¡å‹ç»„ä»¶åç§°",
    "List of tool names": "å·¥å…·åç§°åˆ—è¡¨",
    "List of sub-agent names": "å­ä»£ç†åç§°åˆ—è¡¨",
    "Maximum reasoning-acting iterations": "æœ€å¤§æ¨ç†-è¡ŒåŠ¨è¿­ä»£æ¬¡æ•°",
    "Discard detailed ReAct memory": "ä¸¢å¼ƒè¯¦ç»†çš„ ReAct å†…å­˜",
    "Number of historical conversations to keep": "ä¿ç•™çš„å†å²å¯¹è¯æ•°é‡",
    "Maximum tokens for memory storage": "å†…å­˜å­˜å‚¨çš„æœ€å¤§ä»¤ç‰Œæ•°",
    "Weight for short-term memory in scoring": "çŸ­æœŸå†…å­˜åœ¨è¯„åˆ†ä¸­çš„æƒé‡",
    "Weight for ReAct memory in scoring": "ReAct å†…å­˜åœ¨è¯„åˆ†ä¸­çš„æƒé‡",
    
    # é€šç”¨æè¿°
    "A unique identifier for": "çš„å”¯ä¸€æ ‡è¯†ç¬¦",
    "within the MAS": "åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­",
    "Multi-Agent System": "å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
    "This name is used when calling": "è°ƒç”¨æ—¶ä½¿ç”¨æ­¤åç§°",
    "Indicates whether": "æŒ‡ç¤ºæ˜¯å¦",
    "Only one agent should be marked as master": "åªæœ‰ä¸€ä¸ªä»£ç†åº”æ ‡è®°ä¸ºä¸»ä»£ç†",
    "Name reference to an LLM component": "å¯¹å¤§è¯­è¨€æ¨¡å‹ç»„ä»¶çš„åç§°å¼•ç”¨",
    "registered in the same MAS": "åœ¨åŒä¸€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­æ³¨å†Œ",
    "This LLM will be used for": "æ­¤å¤§è¯­è¨€æ¨¡å‹å°†ç”¨äº",
    "all reasoning steps": "æ‰€æœ‰æ¨ç†æ­¥éª¤",
    "that the agent can invoke": "ä»£ç†å¯ä»¥è°ƒç”¨çš„",
    "Tools must be registered": "å·¥å…·å¿…é¡»æ³¨å†Œ",
    "that this agent can delegate tasks to": "æ­¤ä»£ç†å¯ä»¥å°†ä»»åŠ¡å§”æ‰˜ç»™çš„",
    "Sub-agents must be registered": "å­ä»£ç†å¿…é¡»æ³¨å†Œ",
    "Maximum number of": "æœ€å¤§æ•°é‡",
    "before the agent uses fallback mechanisms": "åœ¨ä»£ç†ä½¿ç”¨åå¤‡æœºåˆ¶ä¹‹å‰",
    "Each round consists of": "æ¯ä¸€è½®åŒ…æ‹¬",
    "one reasoning step and one or more tool executions": "ä¸€ä¸ªæ¨ç†æ­¥éª¤å’Œä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·æ‰§è¡Œ",
    
    # åˆ—è¡¨é¡¹
    "Simple tasks": "ç®€å•ä»»åŠ¡",
    "Multi-step tasks": "å¤šæ­¥éª¤ä»»åŠ¡",
    "Complex reasoning chains": "å¤æ‚æ¨ç†é“¾",
    "rounds": "è½®",
    
    # å†…å­˜ç›¸å…³
    "Controls memory retention strategy": "æ§åˆ¶å†…å­˜ä¿ç•™ç­–ç•¥",
    "Keep only final question-answer pairs": "ä»…ä¿ç•™æœ€ç»ˆé—®ç­”å¯¹",
    "cleaner history": "æ›´æ¸…æ™°çš„å†å²",
    "Retain full ReAct reasoning traces": "ä¿ç•™å®Œæ•´çš„ ReAct æ¨ç†è½¨è¿¹",
    "with weighted scoring": "ä½¿ç”¨åŠ æƒè¯„åˆ†",
    "Number of recent conversation turns": "æœ€è¿‘å¯¹è¯è½®æ¬¡çš„æ•°é‡",
    "to keep in short-term memory": "ä¿ç•™åœ¨çŸ­æœŸå†…å­˜ä¸­",
    "Maximum token limit for the memory system": "å†…å­˜ç³»ç»Ÿçš„æœ€å¤§ä»¤ç‰Œé™åˆ¶",
    "When exceeded, older memories are pruned": "è¶…å‡ºæ—¶ï¼Œè¾ƒæ—§çš„å†…å­˜å°†è¢«ä¿®å‰ª",
    "based on weighted scoring": "åŸºäºåŠ æƒè¯„åˆ†",
    "Relative importance weight for": "ç›¸å¯¹é‡è¦æ€§æƒé‡",
    "when": "å½“",
    "Higher values give more importance to": "è¾ƒé«˜çš„å€¼ä¼šæ›´é‡è§†",
    "recent conversations": "æœ€è¿‘çš„å¯¹è¯",
    "for ReAct intermediate steps": "ç”¨äº ReAct ä¸­é—´æ­¥éª¤",
    
    # æ–¹æ³•ç›¸å…³
    "Execute the agent with given input": "ä½¿ç”¨ç»™å®šè¾“å…¥æ‰§è¡Œä»£ç†",
    "List of message dictionaries": "æ¶ˆæ¯å­—å…¸åˆ—è¡¨",
    "with": "åŒ…å«",
    "and": "å’Œ",
    "fields": "å­—æ®µ",
    "Additional LLM parameters can be passed through": "å¯ä»¥ä¼ é€’é¢å¤–çš„å¤§è¯­è¨€æ¨¡å‹å‚æ•°",
    "object containing": "å¯¹è±¡ï¼ŒåŒ…å«",
    "Final agent response": "æœ€ç»ˆä»£ç†å“åº”",
    "Full conversation history": "å®Œæ•´å¯¹è¯å†å²",
    "Execution metadata": "æ‰§è¡Œå…ƒæ•°æ®",
}

# API æ–‡æ¡£é“¾æ¥æè¿°ç¿»è¯‘
LINK_DESCRIPTIONS = {
    "Chat-based agent API documentation": "åŸºäºèŠå¤©çš„ä»£ç† API æ–‡æ¡£",
    "Parallel agent API documentation": "å¹¶è¡Œä»£ç† API æ–‡æ¡£",
    "Retrieval-Augmented Generation agent API documentation": "æ£€ç´¢å¢å¼ºç”Ÿæˆä»£ç† API æ–‡æ¡£",
    "ReAct pattern-based agent API documentation": "åŸºäº ReAct æ¨¡å¼çš„ä»£ç† API æ–‡æ¡£",
    "Server-Sent Events agent API documentation": "æœåŠ¡å™¨å‘é€äº‹ä»¶ä»£ç† API æ–‡æ¡£",
    "Workflow agent API documentation": "å·¥ä½œæµä»£ç† API æ–‡æ¡£",
    
    "Workflow flow API documentation": "å·¥ä½œæµæµç¨‹ API æ–‡æ¡£",
    "Parallel flow API documentation": "å¹¶è¡Œæµç¨‹ API æ–‡æ¡£",
    "Plan-and-solve flow API documentation": "è®¡åˆ’ä¸æ±‚è§£æµç¨‹ API æ–‡æ¡£",
    "Reflexion flow API documentation": "åæ€æµç¨‹ API æ–‡æ¡£",
    
    "HTTP-based large language model API documentation": "åŸºäº HTTP çš„å¤§è¯­è¨€æ¨¡å‹ API æ–‡æ¡£",
    
    "Function hub API documentation": "å‡½æ•°ä¸­å¿ƒ API æ–‡æ¡£",
    "MCP standard input/output tool API documentation": "MCP æ ‡å‡†è¾“å…¥/è¾“å‡ºå·¥å…· API æ–‡æ¡£",
    "MCP Server-Sent Events tool API documentation": "MCP æœåŠ¡å™¨å‘é€äº‹ä»¶å·¥å…· API æ–‡æ¡£",
    "MCP streamable tool API documentation": "MCP æµå¼å·¥å…· API æ–‡æ¡£",
    
    # Related Documentation
    "Usage guide and examples": "ä½¿ç”¨æŒ‡å—å’Œç¤ºä¾‹",
    "API reference for": "API å‚è€ƒæ–‡æ¡£ï¼š",
    "Available tools documentation": "å¯ç”¨å·¥å…·æ–‡æ¡£",
}

def translate_frontmatter(content):
    """ç¿»è¯‘ frontmatter"""
    lines = content.split('\n')
    result = []
    in_frontmatter = False
    
    for line in lines:
        if line.strip() == '---':
            result.append(line)
            in_frontmatter = not in_frontmatter
            continue
        
        if in_frontmatter:
            if line.startswith('title:'):
                title = line.replace('title:', '').strip()
                # ç¿»è¯‘æ ‡é¢˜
                translated_title = title
                for en, zh in TERM_TRANSLATIONS.items():
                    translated_title = translated_title.replace(en, zh)
                result.append(f'title: {translated_title}')
            elif line.startswith('description:'):
                desc = line.replace('description:', '').strip()
                # ç¿»è¯‘æè¿°
                translated_desc = desc
                for en, zh in TERM_TRANSLATIONS.items():
                    translated_desc = translated_desc.replace(en, zh)
                for en, zh in SENTENCE_TRANSLATIONS.items():
                    translated_desc = translated_desc.replace(en, zh)
                result.append(f'description: {translated_desc}')
            else:
                result.append(line)
        else:
            result.append(line)
    
    return '\n'.join(result)

def translate_headers(content):
    """ç¿»è¯‘æ ‡é¢˜"""
    lines = content.split('\n')
    result = []
    
    for line in lines:
        if line.startswith('#'):
            # æå–æ ‡é¢˜çº§åˆ«å’Œå†…å®¹
            match = re.match(r'^(#+)\s+(.+)$', line)
            if match:
                level, title = match.groups()
                translated_title = title
                # å…ˆç¿»è¯‘æœ¯è¯­
                for en, zh in TERM_TRANSLATIONS.items():
                    translated_title = translated_title.replace(en, zh)
                result.append(f'{level} {translated_title}')
            else:
                result.append(line)
        else:
            result.append(line)
    
    return '\n'.join(result)

def translate_table_headers(content):
    """ç¿»è¯‘è¡¨æ ¼æ ‡é¢˜è¡Œ"""
    lines = content.split('\n')
    result = []
    
    for i, line in enumerate(lines):
        # æ£€æµ‹è¡¨æ ¼æ ‡é¢˜è¡Œ
        if '|' in line and i + 1 < len(lines) and '|---' in lines[i + 1]:
            # è¿™æ˜¯è¡¨æ ¼æ ‡é¢˜è¡Œ
            cells = [cell.strip() for cell in line.split('|')]
            translated_cells = []
            for cell in cells:
                translated_cell = cell
                for en, zh in TERM_TRANSLATIONS.items():
                    if cell == en:
                        translated_cell = zh
                        break
                translated_cells.append(translated_cell)
            result.append('|'.join(translated_cells))
        else:
            result.append(line)
    
    return '\n'.join(result)

def translate_list_items(content):
    """ç¿»è¯‘åˆ—è¡¨é¡¹"""
    lines = content.split('\n')
    result = []
    
    for line in lines:
        if line.strip().startswith(('- ', '* ', '1. ', '2. ', '3. ', '4. ', '5. ')):
            translated_line = line
            # ç¿»è¯‘é“¾æ¥æè¿°
            for en, zh in LINK_DESCRIPTIONS.items():
                translated_line = translated_line.replace(en, zh)
            # ç¿»è¯‘å¥å­
            for en, zh in SENTENCE_TRANSLATIONS.items():
                translated_line = translated_line.replace(en, zh)
            result.append(translated_line)
        else:
            result.append(line)
    
    return '\n'.join(result)

def translate_paragraphs(content):
    """ç¿»è¯‘æ®µè½"""
    # ä¿æŠ¤ä»£ç å—
    code_blocks = []
    def save_code_block(match):
        code_blocks.append(match.group(0))
        return f'__CODE_BLOCK_{len(code_blocks) - 1}__'
    
    # æå–ä»£ç å—
    content = re.sub(r'```[\s\S]*?```', save_code_block, content)
    
    # ç¿»è¯‘æ™®é€šæ®µè½
    lines = content.split('\n')
    result = []
    
    for line in lines:
        if line.strip() and not line.strip().startswith(('#', '|', '-', '*', '```', '1.', '2.', '3.', '4.', '5.')):
            translated_line = line
            # ç¿»è¯‘å®Œæ•´å¥å­
            for en, zh in SENTENCE_TRANSLATIONS.items():
                translated_line = translated_line.replace(en, zh)
            result.append(translated_line)
        else:
            result.append(line)
    
    content = '\n'.join(result)
    
    # æ¢å¤ä»£ç å—
    for i, code_block in enumerate(code_blocks):
        content = content.replace(f'__CODE_BLOCK_{i}__', code_block)
    
    return content

def translate_inline_descriptions(content):
    """ç¿»è¯‘è¡Œå†…æè¿°ï¼ˆè¡¨æ ¼ä¸­çš„æè¿°åˆ—ç­‰ï¼‰"""
    lines = content.split('\n')
    result = []
    
    for line in lines:
        if '|' in line and not '|---' in line:
            # å¯èƒ½æ˜¯è¡¨æ ¼æ•°æ®è¡Œ
            translated_line = line
            for en, zh in SENTENCE_TRANSLATIONS.items():
                translated_line = translated_line.replace(en, zh)
            result.append(translated_line)
        else:
            result.append(line)
    
    return '\n'.join(result)

def translate_content(content, filename):
    """ç¿»è¯‘æ–‡ä»¶å†…å®¹"""
    print(f"  ç¿»è¯‘å†…å®¹...")
    
    # 1. ç¿»è¯‘ frontmatter
    content = translate_frontmatter(content)
    
    # 2. ç¿»è¯‘æ ‡é¢˜
    content = translate_headers(content)
    
    # 3. ç¿»è¯‘è¡¨æ ¼æ ‡é¢˜
    content = translate_table_headers(content)
    
    # 4. ç¿»è¯‘åˆ—è¡¨é¡¹
    content = translate_list_items(content)
    
    # 5. ç¿»è¯‘è¡Œå†…æè¿°
    content = translate_inline_descriptions(content)
    
    # 6. ç¿»è¯‘æ®µè½
    content = translate_paragraphs(content)
    
    return content

def main():
    """ä¸»å‡½æ•°"""
    source_dir = Path("/Users/chengkai48/Documents/AI/oxygent-doc-website/content/oxyapi")
    
    # è·å–æ‰€æœ‰ .mdx æ–‡ä»¶ï¼ˆæ’é™¤ .zh-CN.mdxï¼‰
    mdx_files = [f for f in source_dir.glob("*.mdx")
                 if not f.name.endswith(".zh-CN.mdx")]
    
    print(f"æ‰¾åˆ° {len(mdx_files)} ä¸ªå¾…ç¿»è¯‘æ–‡ä»¶\n")
    
    success_count = 0
    
    for mdx_file in mdx_files:
        output_file = mdx_file.parent / f"{mdx_file.stem}.zh-CN.mdx"
        
        print(f"ç¿»è¯‘: {mdx_file.name} â†’ {output_file.name}")
        
        try:
            with open(mdx_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            translated = translate_content(content, mdx_file.name)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(translated)
            
            print(f"  âœ“ ç¿»è¯‘å®Œæˆ\n")
            success_count += 1
            
        except Exception as e:
            print(f"  âœ— ç¿»è¯‘å¤±è´¥: {e}\n")
    
    print(f"{'='*60}")
    print(f"âœ… ç¿»è¯‘å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(mdx_files)} ä¸ªæ–‡ä»¶")
    
    # æç¤ºåˆ›å»º meta.zh-CN.json
    if success_count > 0:
        print(f"\nğŸ’¡ æç¤ºï¼šåˆ«å¿˜äº†åˆ›å»º meta.zh-CN.json æ–‡ä»¶")

if __name__ == "__main__":
    main()


