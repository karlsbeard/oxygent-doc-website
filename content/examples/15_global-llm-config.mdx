---
title: Global LLM Model Configuration
description: The following uses character matching for simulation. In production environments, typically retrieve top-K relevant content from knowledge base based on query, and can add multi-path retrieval logic
---

## Overview

This example demonstrates global llm model configuration in OxyGent.

## Code

```python
import os
from oxygent import MAS, oxy, Config
from pydantic import Field

Config.set_agent_llm_model("default_llm")   # Globally set llm_model

jd_docs_fh = oxy.FunctionHub(name="jd_docs_tools")

@jd_docs_fh.tool(description="A tool that can retrieve JD-related knowledge")
def retrieval(query: str = Field(description="What aspect of knowledge")) -> str:
    """The following uses character matching for simulation. In production environments, typically retrieve top-K relevant content from knowledge base based on query, and can add multi-path retrieval logic"""
    knowledage_dict = {
        "211_delivery": "**JD 211 Delivery Service**: Orders placed before 11:00 AM (or 10:00 AM in some cities) are delivered the same day; orders placed before 11:00 PM are delivered by 3:00 PM the next day. (Note: Timing starts from order submission for in-stock orders, and from payment completion for prepaid orders)",
        "mission": "JD's mission is 'Technology for a Better Life'.",
        "vision": "JD's vision is to become the world's most trusted company.",
        "values": "JD's core values are: Customer First, Innovation, Fighting Spirit, Responsibility, Gratitude, and Integrity.",
    }
    return "\n\n".join([v for k, v in knowledage_dict.items() if k in query])

oxy_space = [
    oxy.HttpLLM(
        name="default_llm",
        api_key=os.getenv("DEFAULT_LLM_API_KEY"),
        base_url=os.getenv("DEFAULT_LLM_BASE_URL"),
        model_name=os.getenv("DEFAULT_LLM_MODEL_NAME"),
        llm_params={"temperature": 0.1},
    ),
    jd_docs_fh,
    oxy.StdioMCPClient(
        name="time_tools",
        params={
            "command": "uvx",
            "args": ["mcp-server-time", "--local-timezone=Asia/Shanghai"],
        },
    ),
    oxy.StdioMCPClient(
        name="file_tools",
        params={
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", "./local_file"],
        },
    ),
    oxy.ReActAgent(
        name="QA_agent",
        desc="An assistant that can query JD knowledge",
        tools=["jd_docs_tools"],
    ),
    oxy.ReActAgent(
        name="time_agent",
        desc="An assistant that can query time",
        tools=["time_tools"],
    ),
    oxy.ReActAgent(
        name="file_agent",
        desc="An assistant that can operate files",
        tools=["file_tools"],
    ),
    oxy.ReActAgent(
        name="master_agent",
        is_master=True,
        sub_agents=["QA_agent", "time_agent", "file_agent"],
    ),
]

async def main():
    async with MAS(oxy_space=oxy_space) as mas:
        await mas.start_web_service(first_query="What time is it now, record to log.txt in local_file folder")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

## Key Points

- This example shows how to use OxyGent for global llm model configuration
- Follow the code comments for detailed explanations
- Make sure to set up your environment variables before running

## Running the Example

To run this example:

```bash
python 15_global_llm_config.py
```
