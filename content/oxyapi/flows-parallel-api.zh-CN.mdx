---
title: ParallelFlow API 参考
description: ParallelFlow 的完整 API 参考文档，包括构造函数参数和执行方法
icon: Code
---

## 类概述

```python
from oxygent.oxy.flows import ParallelFlow

parallel_flow = ParallelFlow(
    name="data_fetcher",
    desc="从多个数据源并行获取数据",
    permitted_tool_name_list=["tool_1", "tool_2", "tool_3"],
    timeout=100,
    llm_model="default_llm"
)
```

## 构造函数参数

### 核心参数

|参数|类型|默认值|描述|
|-----------|------|---------|-------------|
| `name` | str | 必需 | 并行流程的唯一标识符 |
| `permitted_tool_name_list` | list[str] | 必需 | 要并行执行的工具/代理名称列表 |

### 可选参数

|参数|类型|默认值|描述|
|-----------|------|---------|-------------|
| `desc` | str | "" | 流程用途的描述 |
| `timeout` | int | 100 | 最大执行时间（秒） |
| `llm_model` | str | "default_llm" | 用于后备操作的 LLM 模型名称 |
| `is_permission_required` | bool | False | 执行前是否需要权限 |
| `category` | str | "flow" | 类别分类 |
| `is_master` | bool | False | 是否为主入口点 |

## 参数详情

### `name`
- **类型**：`str`
- **必需**：是
- **描述**：并行流程在多智能体系统中的唯一标识符。通过 `mas.call(callee="flow_name")` 调用流程时使用。

**示例：**
```python
ParallelFlow(
    name="revenue_parallel_flow",
    permitted_tool_name_list=["get_revenue_a", "get_revenue_b", "get_revenue_c"]
)
```

### `permitted_tool_name_list`
- **类型**: `list[str]`
- **必需**: 是（通过 `add_permitted_tools()`）
- **描述**: 将并发执行的工具或代理名称列表。所有工具接收相同的请求并并行执行。

**重要:** 此列表中的所有工具必须在同一个 MAS 实例中注册。

**Example:**
```python
ParallelFlow(
    name="multi_source_fetch",
    permitted_tool_name_list=[
        "database_tool",
        "api_tool",
        "cache_tool"
    ]
)
```

**使用指南:**
- **独立性要求**: 工具应该是独立的，不包含执行依赖关系
- **相同输入**: 所有工具接收相同的 `oxy_request.arguments`
- **最佳数量**: 2-5 个工具可获得速度和可管理性的最佳平衡
- **资源考虑**: 更多工具 = 更多并发操作，需考虑系统限制

### `desc`
- **类型**: `str`
- **默认**: `""`
- **描述**: 此并行流程功能的人类可读描述。

**Example:**
```python
ParallelFlow(
    name="company_data_flow",
    desc="Fetch revenue data for three companies in parallel",
    permitted_tool_name_list=["get_revenue_a", "get_revenue_b", "get_revenue_c"]
)
```

### `timeout`
- **类型**: `int`
- **默认**: `100`
- **描述**: 整个并行流程的最大执行时间（秒）。如果任何工具超过此时间，流程将超时。

**重要:** 由于所有工具并行运行，超时适用于**最慢的工具**。

**使用指南:**
- Fast tools (API calls): 30-60 seconds
- Medium tools (database queries): 60-120 seconds
- Slow tools (complex processing): 120-300 seconds

**Example:**
```python
ParallelFlow(
    name="slow_processors",
    timeout=200,  # 为较慢的工具预留额外时间
    permitted_tool_name_list=["heavy_processor_1", "heavy_processor_2"]
)
```

### `llm_model`
- **类型**: `str`
- **默认**: `"default_llm"`
- **描述**: MAS 中大语言模型组件的名称引用，用于任何后备 LLM 操作。

**Example:**
```python
ParallelFlow(
    name="smart_parallel",
    llm_model="gpt-4",
    permitted_tool_name_list=["analyzer_1", "analyzer_2"]
)
```

### `is_permission_required`
- **类型**: `bool`
- **默认**: `False`
- **描述**: 执行此并行流程前是否需要用户权限。

### `category`
- **类型**: `str`
- **默认**: `"flow"`
- **描述**: 流程的类别分类。从 BaseFlow 继承。

### `is_master`
- **类型**: `bool`
- **默认**: `False`
- **描述**: 此并行流程是否为多智能体系统的主入口点。

**Example:**
```python
ParallelFlow(
    name="master_parallel",
    is_master=True,  # 入口点
    permitted_tool_name_list=["tool_1", "tool_2", "tool_3"]
)
```

## 方法

### `_execute(oxy_request: OxyRequest) -> OxyResponse`

**内部方法** - 并行执行所有允许的工具并聚合结果。

**实现：**
```python
async def _execute(self, oxy_request: OxyRequest) -> OxyResponse:
    # 并发执行所有工具
    oxy_responses = await asyncio.gather(
        *[
            oxy_request.call(
                callee=permitted_tool_name,
                arguments=oxy_request.arguments
            )
            for permitted_tool_name in self.permitted_tool_name_list
        ]
    )

    # 聚合结果
    oxy_response = OxyResponse(
        state=OxyState.COMPLETED,
        output="The following are the results from multiple executions:"
               + "\n".join([res.output for res in oxy_responses])
    )
    return oxy_response
```

**注意:** 这是一个内部方法。用户应通过 `mas.call()` 或 `oxy_request.call()` 调用。

## 执行流程

```
User Request
    ↓
OxyRequest Created with arguments
    ↓
ParallelFlow._execute() Called
    ↓
    ┌───────────────┬───────────────┬───────────────┐
    ↓               ↓               ↓               ↓
Tool 1 Exec     Tool 2 Exec     Tool 3 Exec    ...
(parallel)      (parallel)      (parallel)
    ↓               ↓               ↓               ↓
Response 1      Response 2      Response 3      ...
    └───────────────┴───────────────┴───────────────┘
                        ↓
            await asyncio.gather()
                        ↓
            Aggregate All Outputs
                        ↓
    OxyResponse (state=COMPLETED)
    output = "Results:\nTool1: ...\nTool2: ...\nTool3: ..."
                        ↓
            Return to User
```

## Return Value

### OxyResponse Structure

```python
{
    "state": OxyState.COMPLETED,
    "output": "The following are the results from multiple executions:\n" +
              "Tool1 result\nTool2 result\nTool3 result"
}
```

**输出格式:**
- 前缀: "The following are the results from multiple executions:"
- Each tool result on a new line
- Results in the order of `permitted_tool_name_list`

## Usage 示例s

### Basic Parallel Data Fetching

```python
from oxygent import MAS, oxy
import asyncio

fh = oxy.FunctionHub(name="data_tools")

@fh.tool(description="获取公司 A 的收入")
async def get_revenue_a():
    await asyncio.sleep(2)  # 模拟 API 调用
    return "Company A revenue: $10M"

@fh.tool(description="获取公司 B 的收入")
async def get_revenue_b():
    await asyncio.sleep(3)  # 模拟 API 调用
    return "Company B revenue: $15M"

@fh.tool(description="获取公司 C 的收入")
async def get_revenue_c():
    await asyncio.sleep(1)  # 模拟 API 调用
    return "Company C revenue: $8M"

oxy_space = [
    oxy.HttpLLM(name="default_llm", ...),
    fh,
    oxy.flows.ParallelFlow(
        name="revenue_parallel_flow",
        desc="Fetch revenue data for three companies in parallel",
        permitted_tool_name_list=[
            "get_revenue_a",
            "get_revenue_b",
            "get_revenue_c"
        ]
    )
]

async def main():
    async with MAS(oxy_space=oxy_space) as mas:
        result = await mas.call(
            callee="revenue_parallel_flow",
            arguments={}
        )
        print(result.output)
        # 输出:
        # The following are the results from multiple executions:
        # Company A revenue: $10M
        # Company B revenue: $15M
        # Company C revenue: $8M

asyncio.run(main())
```

### 并行代理执行

```python
oxy_space = [
    oxy.HttpLLM(name="default_llm", ...),
    oxy.ReActAgent(
        name="analyzer_agent",
        llm_model="default_llm",
        tools=[...]
    ),
    oxy.ReActAgent(
        name="summarizer_agent",
        llm_model="default_llm",
        tools=[...]
    ),
    oxy.ReActAgent(
        name="classifier_agent",
        llm_model="default_llm",
        tools=[...]
    ),
    oxy.flows.ParallelFlow(
        name="multi_agent_parallel",
        desc="并行执行多个分析代理",
        permitted_tool_name_list=[
            "analyzer_agent",
            "summarizer_agent",
            "classifier_agent"
        ]
    )
]
```

### 嵌套在 ReActAgent 中

```python
oxy_space = [
    oxy.HttpLLM(name="default_llm", ...),
    fh,  # 包含工具的 FunctionHub
    oxy.flows.ParallelFlow(
        name="parallel_data_fetch",
        permitted_tool_name_list=["tool_1", "tool_2", "tool_3"]
    ),
    oxy.ReActAgent(
        name="master_agent",
        is_master=True,
        sub_agents=["parallel_data_fetch"],
        llm_model="default_llm",
        additional_prompt="分析并整理并行执行结果"
    )
]
```

### 使用自定义超时

```python
oxy.flows.ParallelFlow(
    name="long_running_parallel",
    desc="并行执行慢速操作",
    permitted_tool_name_list=[
        "slow_processor_1",
        "slow_processor_2",
        "slow_processor_3"
    ],
    timeout=300  # 慢速操作的 5 分钟超时
)
```

## 最佳实践

### 1. 确保工具独立性

`permitted_tool_name_list` 中的工具应该是独立的：

```python
# ✅ 好的：独立的数据获取器
ParallelFlow(
    name="good_parallel",
    permitted_tool_name_list=[
        "fetch_from_db",      # 独立的
        "fetch_from_api",     # 独立的
        "fetch_from_cache"    # 独立的
    ]
)

# ❌ 不好的：依赖工具（tool_2 需要 tool_1 的结果）
ParallelFlow(
    name="bad_parallel",
    permitted_tool_name_list=[
        "preprocess_data",    # 必须先运行
        "analyze_data"        # 需要预处理的数据
    ]
)
```

### 2. 设置合适的超时时间

基于预期最慢工具设置超时时间：

```python
# 如果最慢的工具需要约 60 秒，则将超时设置为 90-120 秒
ParallelFlow(
    name="data_parallel",
    timeout=120,  # 为最慢的工具预留额外缓冲时间
    permitted_tool_name_list=[...]
)
```

### 3. 限制并行数量

保持并行工具数量合理：

```python
# ✅ 好的：2-5 个并行工具
ParallelFlow(
    name="optimal_parallel",
    permitted_tool_name_list=["tool_1", "tool_2", "tool_3"]  # 3 个工具
)

# ⚠️ 注意：10+ 个并行工具可能导致资源问题
ParallelFlow(
    name="heavy_parallel",
    permitted_tool_name_list=["tool_1", ..., "tool_20"]  # 20 个工具
)
```

### 4. 使用 ParallelAgent 进行智能汇总

如果您需要对并行结果进行智能汇总，请使用 `ParallelAgent`：

```python
# 用于简单聚合：ParallelFlow
ParallelFlow(name="simple_parallel", ...)

# 用于智能汇总：ParallelAgent
oxy.ParallelAgent(
    name="smart_parallel",
    llm_model="gpt-4",
    ...
)
```

### 5. 处理工具故障

考虑如果一个工具失败会发生什么：

```python
# ParallelFlow 会传播异常
# 如果任何工具失败，整个流程都会失败

# 为了容错，将工具包装在错误处理中：
@fh.tool(description="容错工具")
async def resilient_tool():
    try:
        result = await risky_operation()
        return result
    except Exception as e:
        return f"Error: {str(e)}"  # 将错误作为字符串返回而不是抛出异常
```

## 性能考虑

### 并行化优势

**时间节省：**
- 顺序执行：T1 + T2 + T3
- 并行执行：max(T1, T2, T3)

**示例：**
```python
# 顺序执行（使用 Workflow 或普通代理调用）
# 工具 A：5秒，工具 B：3秒，工具 C：4秒
# 总计：5 + 3 + 4 = 12 秒

# 并行执行（使用 ParallelFlow）
# 总计：max(5, 3, 4) = 5 秒
# 加速：12/5 = 2.4倍更快
```

### 资源使用

**并发执行：**
- CPU：所有工具同时执行
- 内存：所有工具加载到内存中
- 网络：所有网络调用并发进行

**建议：**
- 在包含许多并行工具时监控系统资源
- 考虑使用信号量进行速率限制（例如，在 HttpLLM 中）

### 超时策略

**最佳实践：**
```python
# 估计最大工具时间：60秒
# 添加缓冲：60秒 * 1.5 = 90秒
# 设置超时：90秒（或整数 100秒）

ParallelFlow(
    name="data_flow",
    timeout=100,
    permitted_tool_name_list=[...]
)
```

## 常见模式

### 模式：数据聚合

```python
# 从多个数据源获取数据并聚合
ParallelFlow(
    name="multi_source_data",
    desc="同时从数据库、API 和缓存获取数据",
    permitted_tool_name_list=[
        "database_reader",
        "api_fetcher",
        "cache_reader"
    ]
)
```

### 模式：并行分析

```python
# 对相同数据运行多种分析
ParallelFlow(
    name="multi_perspective_analysis",
    desc="同时从不同角度分析数据",
    permitted_tool_name_list=[
        "sentiment_analyzer",
        "topic_classifier",
        "entity_extractor"
    ]
)
```

### 模式：冗余提高可靠性

```python
# 查询多个冗余源以提高可靠性
ParallelFlow(
    name="redundant_fetch",
    desc="从多个冗余源获取数据，使用最快/最佳结果",
    permitted_tool_name_list=[
        "primary_api",
        "backup_api",
        "fallback_api"
    ]
)
```

## 与其他流程的比较

|Feature|ParallelFlow|Workflow|PlanAndSolve|
|---------|--------------|----------|--------------|
| **执行方式** | 并发 | 自定义逻辑 | 顺序步骤 |
| **工具依赖** | 独立 | 任意 | 依赖步骤 |
| **结果聚合** | 简单连接 | 自定义 | 不适用 |
| **使用场景** | 并行数据获取 | 自定义模式 | 多步骤计划 |
| **复杂度** | 低 | 可变 | 高 |

## Related API 参考

- [Workflow API](/oxyapi/flows-workflow-api) - 自定义工作流 API
- [PlanAndSolve API](/oxyapi/flows-plan-and-solve-api) - 计划执行流 API
- [Reflexion API](/oxyapi/flows-reflexion-api) - 自我评估流 API
- [ParallelAgent API](/oxyapi/agents-parallel-api) - 智能并行代理 API
