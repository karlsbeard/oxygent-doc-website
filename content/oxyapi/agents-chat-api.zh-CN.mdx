---
title: ChatAgent API 参考
description: ChatAgent 类的完整 API 参考文档，包括构造函数参数、方法和使用示例
icon: MessageSquare
---

## 类概述

```python
from oxygent.oxy import ChatAgent

class ChatAgent(LocalAgent):
    """管理与语言模型聊天交互的对话代理。"""
```

ChatAgent 继承自 `LocalAgent`，提供基础对话功能，包括对话历史管理、用户查询处理和语言模型协调。

## 构造函数

### ChatAgent()

```python
ChatAgent(
    name: str,
    desc: str,
    llm_model: str,
    prompt: Optional[str] = "You are a helpful assistant.",
    **kwargs
)
```

#### 参数

|参数|类型|默认值|描述|
|-----------|------|---------|-------------|
| `name` | `str` | 必需 | 用于标识和调用的代理名称 |
| `desc` | `str` | 必需 | 解释代理功能的描述 |
| `llm_model` | `str` | 必需 | 要使用的大语言模型标识符 |
| `prompt` | `可选[str]` | `"You are a helpful assistant."` | 定义代理行为的系统提示 |

#### 继承参数（来自 LocalAgent）

|参数|类型|默认值|描述|
|-----------|------|---------|-------------|
| `additional_prompt` | `可选[str]` | `""` | 额外的用户自定义提示 |
| `sub_agents` | `可选[list]` | `[]` | 此代理可以委托的其他代理名称列表 |
| `tools` | `可选[list]` | `[]` | 此代理可用的工具列表 |
| `except_tools` | `可选[list]` | `[]` | 此代理明确禁止使用的工具列表 |
| `is_sourcing_tools` | `bool` | `False` | 是否启用动态工具检索 |
| `top_k_tools` | `int` | `10` | 要检索的工具数量 |
| `short_memory_size` | `int` | 配置默认值 | 要保留的短期内存条目数 |
| `is_retain_master_short_memory` | `bool` | `False` | 是否检索用户历史 |
| `is_multimodal_supported` | `bool` | `False` | 是否支持多模态输入 |
| `team_size` | `int` | `1` | 团队执行的实例数 |

#### 继承参数（来自 BaseAgent）

|参数|类型|默认值|描述|
|-----------|------|---------|-------------|
| `category` | `str` | `"agent"` | 工具/代理类别 |
| `input_schema` | `dict[str, Any]` | 配置默认值 | 输入参数模式 |

#### 继承参数（来自 BaseFlow）

|参数|类型|默认值|描述|
|-----------|------|---------|-------------|
| `is_master` | `bool` | `False` | 此代理是否为主代理 |
| `timeout` | `int` | `300` | 执行超时时间（秒） |
| `func_process_input` | `可选[Callable]` | `None` | 输入处理函数 |
| `func_process_output` | `可选[Callable]` | `None` | 输出处理函数 |
| `func_format_input` | `可选[Callable]` | `None` | 输入格式化函数 |
| `func_format_output` | `可选[Callable]` | `None` | 输出格式化函数 |
| `permitted_tool_name_list` | `list` | `[]` | 允许的工具名称列表 |

## 方法

### _execute()

```python
async def _execute(self, oxy_request: OxyRequest) -> OxyResponse
```

执行与语言模型的聊天交互。

#### 参数

|参数|类型|描述|
|-----------|------|-------------|
| `oxy_request` | `OxyRequest` | 包含用户查询、对话历史和额外参数的请求对象 |

#### 返回值

|类型|描述|
|------|-------------|
| `OxyResponse` | 包含生成答案的语言模型响应 |

#### 执行流程

1. **创建临时内存**：创建一个新的 Memory 对象来管理对话
2. **添加系统消息**：使用构建的指令添加系统提示
3. **加载短期内存**：添加最近的对话历史
4. **添加用户查询**：追加当前用户查询以继续多轮对话
5. **调用语言模型**：准备参数并调用配置的 LLM
6. **返回响应**：返回 LLM 响应

### set_default_prompt()

```python
@model_validator(mode="after")
def set_default_prompt(self) -> "ChatAgent"
```

模型验证器，如果未提供则设置默认提示。

#### 返回值

|类型|描述|
|------|-------------|
| `ChatAgent` | 返回自身实例 |

### 继承方法

ChatAgent 继承以下方法：

#### 来自 LocalAgent

- `init()` - 初始化代理并设置团队执行
- `_get_history()` - 从 Elasticsearch 检索对话历史
- `_get_llm_tool_desc_list()` - 获取 LLM 上下文的工具描述
- `_build_instruction()` - 通过替换模板变量构建指令提示
- `_pre_process()` - 预处理请求以加载对话历史
- `_before_execute()` - 为 LLM 执行准备工具描述

#### 来自 BaseAgent

- `_pre_save_data()` - 在处理前保存初步追踪数据

#### 来自 BaseFlow

- `call()` - 执行代理并处理请求
- `add_permitted_tool()` - 将允许的工具添加到列表
- `set_mas()` - 设置多智能体系统引用

## 使用示例

### 基础用法

```python
from oxygent import MAS, OxySpace
from oxygent.oxy import ChatAgent, HttpLLM

# 创建 OxySpace 并注册组件
oxy_space = [
    HttpLLM(
        name="default_llm",
        api_key="your-api-key",
        base_url="https://api.openai.com/v1",
        model_name="gpt-3.5-turbo"
    ),
    ChatAgent(
        name="chat_agent",
        desc="基础聊天代理",
        llm_model="default_llm",
        prompt="You are a helpful assistant."
    )
]

# 使用 ChatAgent 进行对话
async def main():
    async with MAS(oxy_space=oxy_space) as mas:
        result = await mas.call(
            callee="chat_agent",
            arguments={"query": "你好，请介绍一下你自己。"}
        )
        print(result.output)
```

### 自定义提示

```python
ChatAgent(
    name="specialized_agent",
    desc="专业客服代理",
    llm_model="default_llm",
    prompt="你是一名专业的客户服务代表。"
           "始终保持礼貌、乐于助人，并提供准确的信息。"
)
```

### 内存管理

```python
ChatAgent(
    name="memory_agent",
    desc="带内存管理的聊天代理",
    llm_model="default_llm",
    short_memory_size=20,  # 保留 20 轮对话
    is_retain_master_short_memory=True  # 保留用户级历史
)
```

### 团队执行模式

```python
ChatAgent(
    name="team_agent",
    desc="团队协作聊天代理",
    llm_model="default_llm",
    team_size=3,  # 创建 3 个并行实例
    is_master=True
)
```

## 配置选项

### 内存管理

- `short_memory_size`：控制保留的对话轮次数
- `is_retain_master_short_memory`：是否保留用户级对话历史

### 提示配置

- `prompt`：主系统提示
- `additional_prompt`：额外的用户自定义提示

### 团队执行

- `team_size`：并行执行实例数（当 >1 时创建 ParallelAgent）

## 错误处理

### 常见错误

1. **缺少 LLM 模型**
   ```python
   # 错误：未设置 llm_model
   ChatAgent(name="agent", desc="test")  # 抛出异常

   # 正确：设置 llm_model
   ChatAgent(name="agent", desc="test", llm_model="default_llm")
   ```

2. **LLM 模型未找到**
   ```python
   # 确保 LLM 模型在 MAS 中注册
   oxy_space = [
       HttpLLM(name="my_llm", ...),  # 首先注册 LLM
       ChatAgent(llm_model="my_llm", ...)  # 然后引用它
   ]
   ```

## 性能考虑

### 内存管理

- 较大的 `short_memory_size` 会增加 LLM 调用中的令牌消耗
- 建议根据实际需求设置适当的内存大小

### 团队执行

- `team_size > 1` 会创建多个代理实例进行并行执行
- 适用于需要多样化响应的场景

## 相关链接

- [ChatAgent 主文档](/docs/agents-chat) - 概述和使用指南
- [ReActAgent API](/oxyapi/agents-react-api) - 更复杂的推理代理
- [ParallelAgent API](/oxyapi/agents-parallel-api) - 并行执行代理
- [WorkflowAgent API](/oxyapi/agents-workflow-api) - 工作流代理
